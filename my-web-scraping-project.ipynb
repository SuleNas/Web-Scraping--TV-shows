{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV SHOWS WEB SCRAPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. It is about downloading structured data from the web, selecting some of that data, and passing along what you selected to another process.\n",
    "\n",
    "The idea is to go through a website of interest and, using special python programming libraries, extract relevant data/information that can be presented as a DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This web scraping project  explores the 200 most popular TV Shows on themoviedb.org in descending order. One challenge is that we will have to parse in several pages to extract these informations as all 200 TV Shows are not on the same web page.\n",
    "\n",
    "Below are the steps i will be taking:\n",
    "\n",
    "1. download the web page using requests library.\n",
    "2.  parse the HTML source code using BeautifulSoup.\n",
    "3.  Extract show name, release date and web link.\n",
    "4.  Get links and information of 9 other pages to complete 200 TV shows.\n",
    "\n",
    "5.  Create a Dataframe and save the information as a CSV file.\n",
    "6. Get info about a TV series using its web link.\n",
    "7. Create a dataframe containing some TV Show's details.\n",
    "8. Scrape all shows and create their csv files containing some of their info.\n",
    "9. Create a folder to store all the created csv files.\n",
    "\n",
    "\n",
    "I will extracting the below information for each TV Show.\n",
    "- creator\n",
    "- description\n",
    "- genre\n",
    "- viewer age suitability\n",
    "- Top casts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![themoviedb.png](https://i.imgur.com/YmsoDPT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be creating functions that will help me get the above stated information easily and then write and save the data obtained as a csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's prepare the environment by installing jovian, naming the project and saving the notebook. You can run this notebook by clicking the \"Run\" button above the notebook and choosing \"Run on Binder\" option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"web-scraper\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Web Page Using Requests Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install the requests library that will help me download the website i want to scrap.\n",
    "\n",
    "!pip install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define website to scrap and store the link.\n",
    "shows_url = 'https://www.themoviedb.org/tv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(shows_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A successful request download should have the value between 200 - 299. We can confirm this using the .status_code property of the request library as done below. Check out this link to know more about status code : https://developer.mozilla.org/en-US/docs/Web/HTTP/Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the web page was successfully downloaded\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a sample of what our downloaded page looks like as well as the length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the content of our downloaded page into a file 'shows-data.html'. To view this file, either as a web page or HTML file, we can go to file at the top-left of this notebook and click open. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can write page content to a file 'Shows-data.html'\n",
    "with open('shows-data.html', 'w') as shows:\n",
    "    shows.write(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using BeautifulSoup, we can explore the page-contents, and finding our data in whichever HTML tags they might be enclosed in. Click this link to learn more about HTML tags: https://www.javatpoint.com/html-tags#:~:text=HTML%20tags%20are%20like%20keywords,tag%2C%20content%20and%20closing%20tag.&text=Every%20tag%20in%20HTML%20perform%20different%20tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse HTML Code Using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup is a python library used for pulling data out of HTML and XML files.\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-using-tag-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install BeautifulSoup Python library  for pulling data out of HTML files\n",
    "\n",
    "!pip install beautifulsoup4 --upgrade --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a BeautifulSoup object called 'docu' containing all the html\n",
    "docu = BeautifulSoup(page_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a helper function 'create_doc' that will take a url as an argument and carry out all the process we followed above to return a BeautifulSoup object. \n",
    "\n",
    "Functions make our work easier by reducing multiple lines of code needed to get an information to just one or two lines. These functions come in handy especially when it involves repeated operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc(url):\n",
    "    # download page using requests lib.\n",
    "    response1 = requests.get(url)\n",
    "    # check if the web page was successfully downloaded else raise an exception.\n",
    "    if response1.status_code != 200:\n",
    "        return \"Page not successfully downloaded\"\n",
    "    contents = response1.text\n",
    "    \n",
    "    # convert contents into BeautifulSoup object\n",
    "    docs = BeautifulSoup(contents, 'html.parser')\n",
    "    return docs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some popular tags that will really come in handy for this projects are the Div, h2, p, and a tags, along with attributes such as 'href' and 'class'. Most of the information we seek to extract will be enclosed in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have been able to download our web page of interest using the requests library, saving its content as a html file and then parsing using the BeautifulSoup Library in order to be able to extract required information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Show Name, Release Date And Web Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By right-clicking and choosing the 'inspect option on this page, we can see that a form of dialogue box pops out at the bottom that shows us the HTML codes that make up this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img.png](https://i.imgur.com/7V51ubA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the highlighted sections, we can see that a show's title is inside an a-tag. While the a-tag is a child of a h2-tag.\n",
    "\n",
    "\n",
    "Note that there are more than 200 TV shows on this website, with 20 shows on each web page. Notice the \"page_1\" written after the div-tag with 'id' attribute = page_1\n",
    "\n",
    "As stated earlier, will not be able to get all 200 TV shows from our downloaded page. To get more, we will need to click on a 'load more' button just under the page. That means me need to get 9 more links that we can download and obtain their informations. We will call them page_2, page_3, page_4 and page_5, page_6, page_7, page_8, page_9, page_10.\n",
    "\n",
    "Before we get these other links, let's use our present 'docu' object to extract required information and then create a function that will make it easier for us to get the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find the 'h2' and 'a' tags using the find_all property of BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2 tags\n",
    "h2_tags = docu.find_all('h2')\n",
    "len(h2_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_tags\n",
    "a_tags = docu.find_all('a')\n",
    "len(a_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sample of the a-tags\n",
    "a_tags[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the \".text\" property to get only the important text from the a_tag above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags[2].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a python 'for' loop, we want to extract all a-tags that are inside a h2-tag to get the Titles, just as seen in the image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An empty list that we will append all the Titles into.\n",
    "Titles = []\n",
    "# iterating through the h2 tags\n",
    "for h2 in h2_tags:\n",
    "    #iterating through the a tags\n",
    "    for title in a_tags:\n",
    "        \n",
    "        if title in h2:\n",
    "            Titles.append(title.text)\n",
    "\n",
    "print(Titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that there are 20 Titles on the first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, let's create and test a helper function that will take in a h2 and a-tags as argument and return the titles as output easily with just a line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(h2_tag,a_tag):\n",
    "    # An empty list that we will append all the Titles into.\n",
    "    titles = []\n",
    "    # iterating through the h2 tags\n",
    "    for h2 in h2_tag:\n",
    "        #iterating through the a tags\n",
    "        for title in a_tag:\n",
    "        \n",
    "            if title in h2:\n",
    "                titles.append(title.text)\n",
    "\n",
    "    return titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles = get_titles(h2_tags,a_tags)\n",
    "Titles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link to each TV series on the page is represented by unique numbers inside the 'href' attribute of an a-tag which is in a h2-tag as seen in the image above.\n",
    "\n",
    "\n",
    "see this example in the cell below. It shows the link in 'href' attribute to a particular TV series. But this link is incomplete, so we will try to fix that in a 'for' loop by adding a base url to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_tags[5].a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An empty list that we will append all the links into.\n",
    "Link = []\n",
    "# Define a base url\n",
    "Base_url = 'https://www.themoviedb.org'\n",
    "\n",
    "# iterating through the h2 tags\n",
    "for h2 in h2_tags:\n",
    "    #iterating through the a tags\n",
    "    for links in a_tags:\n",
    "        if links in h2:\n",
    "            Link.append(Base_url+links['href'])\n",
    "            \n",
    "print(Link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a helper function that will take in h2 and a-tags as argument and return a show's link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(h2_tag,a_tag):\n",
    "    # An empty list that we will append all the links into.\n",
    "    links = []\n",
    "    \n",
    "    # Define a base url\n",
    "    base_url = 'https://www.themoviedb.org'\n",
    "    \n",
    "    # iterating through the h2 tags\n",
    "    for h2 in h2_tag:\n",
    "        #iterating through the a tags\n",
    "        for lnk in a_tag:\n",
    "            if lnk in h2:\n",
    "                links.append(Base_url+lnk['href'])\n",
    "                \n",
    "    return links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Links = get_links(h2_tags,a_tags)\n",
    "Links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The release date is in a p-tag. The p-tag is in a div-tag of class 'content'. So let's find the 'p' and 'div' tags as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img2.png](https://i.imgur.com/keLEkjm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tags = docu.find_all('p')\n",
    "len(p_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tags = docu.find_all('div', class_ = 'content')\n",
    "len(div_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_dates = []\n",
    "# iterating through the div_tags\n",
    "for div in div_tags:\n",
    "    #iterating through the p tags\n",
    "    for p in p_tags:\n",
    "        \n",
    "        if p in div:\n",
    "            release_dates.append(p.text)\n",
    "print(release_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can equally create a helper function for the dates with the p and div-tags as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates(div_tag,p_tag):\n",
    "    rls_dates = []\n",
    "    # iterating through the div_tags\n",
    "    for div in div_tag:\n",
    "        \n",
    "        #iterating through the p tags\n",
    "        for p in p_tag:\n",
    "            if p in div:\n",
    "                \n",
    "                date = p.text\n",
    "                # iterate to check if date is empty\n",
    "                if not date:\n",
    "                    rls_dates.append('NO DATE GIVEN')\n",
    "                else:\n",
    "                    rls_dates.append(date)\n",
    "                    \n",
    "    \n",
    "    return rls_dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_date = dates(div_tags,p_tags)\n",
    "release_date[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have been able to extract the Shows' Titles, Release Dates and their individual links. Let's create a function that takes a url and returns all these 3 information using all our already defined functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV_Shows(url):\n",
    "    \n",
    "    # download page using requests lib and create a BeautifulSoup object.\n",
    "    \n",
    "    Docs = create_doc(url)\n",
    "    \n",
    "    # Define necessary tags\n",
    "    \n",
    "    h2_tages = Docs.find_all('h2')\n",
    "    a_tages = Docs.find_all('a')\n",
    "    p_tages = Docs.find_all('p')\n",
    "    div_tages = Docs.find_all('div', class_ = 'content')\n",
    "    \n",
    "    # Get titles\n",
    "    \n",
    "    Title = get_titles(h2_tages,a_tages)\n",
    "    \n",
    "    # Get links\n",
    "    Links = get_links(h2_tages,a_tages)\n",
    "    \n",
    "    # get release dates\n",
    "    \n",
    "    Released_on = dates(div_tages, p_tages)\n",
    "    \n",
    "    return Title, Links, Released_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this function using our intial shows url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_1 = TV_Shows(shows_url)\n",
    "page_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, let's save a copy of our work to avoid losing it due to timeout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Links and Extract Information of 9 Other Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the links that will take us to the other 9 pages containing 20 TV Shows each where we will be able to get same informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img3.png](https://i.imgur.com/2AHwAME.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the image above, the \"Load More\" link is in an a-tag of class attribute \"no_click load_more\".\n",
    "Let's find it using .find_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = docu.find_all('a', class_ = 'no_click load_more')\n",
    "load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 items in the list, but we are only interested in the second one, i.e index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = load[1]['href']\n",
    "next_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the last character in the output for the 'next_page' variable above. It is indicating the next page number. We can obtain any page number by changing that last character to whichever page number we desire and then adding a base url to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.themoviedb.org'\n",
    "base_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the links for page 2 - 10 using a 'for loop'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_links = []\n",
    "for i in range(2,11):\n",
    "    base_url = 'https://www.themoviedb.org'\n",
    "    # All characters of 'next_page', except the last one, is added to i which is converted to a string\n",
    "    x = next_page[:-1] + str(i)\n",
    "    page_links.append(base_url + x)\n",
    "print(page_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new list containing all the links to the 10 pages we are interested in. \n",
    "\n",
    "First, we will convert our initial shows_url to a list object and then add it to the 9 other page links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1_url = list(shows_url.split(\"/n\"))\n",
    "page1_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new list containing links to all 5 pages\n",
    "pages_urls = page1_url + page_links\n",
    "pages_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extract 200 show Titles with their release dates and links using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles = []\n",
    "Release_Dates = []\n",
    "URLs = []\n",
    "\n",
    "for url in pages_urls:\n",
    "    series = TV_Shows(url)\n",
    "    Titles.append(series[0])\n",
    "    Release_Dates.append(series[2])\n",
    "    URLs.append(series[1])\n",
    "    \n",
    "# print the Titles to see sample of output\n",
    "print(Titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the outputs above, we can see that it is actually a list containing 10 list items. But we want each of our outputs to be in a single list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can acheive this using the itertools. The itertools is a module in Python having a collection of functions that are used for handling iterators. They make iterating through the iterables like lists and strings very easy. One of such functions is the chain().\n",
    "\n",
    "https://www.geeksforgeeks.org/python-itertools-chain/#:~:text=chain()%20function,thus%20explicitly%20converted%20into%20iterables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles = list(chain(*Titles))\n",
    "len(Titles), Titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Release_Date = list(chain(*Release_Dates))\n",
    "len(Release_Date), Release_Date[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there is something wrong with the released date, because its supposed to contain 200 items, yet we are getting 202.\n",
    "Lets view the first 100 to see what the problem might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Release_Date[:101]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing, we can see that there are some duplication of entries on indexes 66-67 and 69-70.\n",
    "Not sure what could be the reason but we can remove the duplicates manually so as to continue with our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new variable\n",
    "Released_on = Release_Date\n",
    "len(Released_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's list the indexes to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [67,70]\n",
    "for index in sorted(indexes, reverse=True):\n",
    "    del Released_on[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Released_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the shows URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_URL = list(chain(*URLs))\n",
    "len(Show_URL), Show_URL[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all 200 TV Shows with their Titles, Release dates and links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To create a Pandas Dataframe and a CSV file for The TV Shows\n",
    "\n",
    "Now that i have the Title, release date and links to each of the 200 most popular shows on this website, i will like to create a dataframe using pandas.\n",
    "\n",
    "Pandas is an open-source Python library used for data analysis and manipulation. In particular, it offers data structures and operations for manipulating numerical tables and time series\n",
    "\n",
    "First off, i will have to import the pandas library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dictionary with key titles Show Titles, Date released and show link and attach our scrapped information as value to each key respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Show Title':Titles,\n",
    "       'Date Released': Released_on,\n",
    "       'Show Link': Show_URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe\n",
    "TV_shows_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TV_shows_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a way of truncating a dataframe with large rows or columns, hence we can only view the first and last five in the dataframe. Of course there are other ways to view the whole content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write and save this dataframe as a csv file. To access this file, we can click the file button on the top-left of this page and then click open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as a csv file and drop the index column(numbers)\n",
    "TV_shows_df.to_csv('TVShows.csv',index= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a  sample view of the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head TVShows.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(files= ['TVShows.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Information About A TV Series Using Its Link\n",
    "\n",
    "As stated in the project objectives, i will be trying to obtain the following information for each TV show:\n",
    "\n",
    "- creator\n",
    "- description\n",
    "- genre\n",
    "- parental guidlines\n",
    "- Top casts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the link to the second TV series,'The Falcon and the Winter Soldier', to obtain information about that particular series. And then use the method followed to get similar info about the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://i.imgur.com/PqKRAX4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series_url = Show_URL[1]\n",
    "Series_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets obtain a BeautifulSoup object using our previously defined function 'create_doc(url)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docu2 = create_doc(Series_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me get some important tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags2 = docu2.find_all('a')\n",
    "len(a_tags2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tags2 =docu2.find_all('p')\n",
    "len(p_tags2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATOR..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://i.imgur.com/rH5MzsF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the image above, the creator name is in an a-tag inside an li-tag with class name 'profile'.\n",
    "\n",
    "But the a-tag is also inside a p-tag, so i will try to access the p-tag as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_tag = docu2.find_all('li',class_ = 'profile')\n",
    "li_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = li_tag[0].p.text\n",
    "creator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it is also possible that there can be more than one person as the show creator or that the show creator's name was not mentioned on the web page. Hence, we will put all these into consideration while writing a function for finding the show's creator(s).\n",
    "\n",
    "We will also need to get the ol-tags with class attribute 'people no_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showmaker(showurl):\n",
    "    # create a Beautifulsoup object\n",
    "    doc = create_doc(showurl)\n",
    "    \n",
    "    # Get li-tags and ol-tags\n",
    "    ol_tags = doc.find_all('ol', class_ = 'people no_image')\n",
    "    li_tags = doc.find_all('li',class_ = 'profile')\n",
    "    \n",
    "    # create a list for adding all creators \n",
    "    creators = []\n",
    "    \n",
    "    for ol in ol_tags:\n",
    "        for li in li_tags:\n",
    "            # Check if li tags are in ol tags\n",
    "            if li in ol:\n",
    "                # Add all li creator texts to the creator list\n",
    "                creators.append(li.p.text)\n",
    "                \n",
    "    # If creator name is not given:     \n",
    "    if len(creators) == 0:\n",
    "        return \"Creator name not Given\"\n",
    "    # Return list of creators\n",
    "    return creators\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showmaker(Show_URL[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showmaker(Show_URL[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DESCRIPTION..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TV series description is in the div tag of class 'overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tag = docu2.find('div', class_ = 'overview')\n",
    "overview = div_tag.text.strip()\n",
    "overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function for the show's description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Description(showurl):\n",
    "    # download Show page and create a Beautifulsoup object\n",
    "    doc1 = create_doc(showurl)\n",
    "   \n",
    "    # Find div-tags\n",
    "    div_tags = doc1.find('div', class_ = 'overview')\n",
    "    overview = div_tags.text.strip()\n",
    "    \n",
    "    # If no overview given...\n",
    "    if len(overview) == 0:\n",
    "        return \"No Overview Given\"\n",
    "    return overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Description(Show_URL[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENRE..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The show's genre is in the span-tag with class name 'genres'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://i.imgur.com/Ov5lGLM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = docu2.find_all('span', class_ = 'genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genres = []\n",
    "for g in genre:\n",
    "    for a in a_tags2:\n",
    "        if a in g:\n",
    "            Genres.append(a.text)\n",
    "print(Genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function for the show's genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Genre(showurl):\n",
    "    # download Show page and create a Beautifulsoup object\n",
    "    doc1 = create_doc(showurl)\n",
    "   \n",
    "    genre = doc1.find_all('span', class_ = 'genres')\n",
    "    a_tag = doc1.find_all('a')\n",
    "    \n",
    "    Genres = []\n",
    "    for g in genre:\n",
    "        for a in a_tag:\n",
    "            if a in g:\n",
    "                Genres.append(a.text)\n",
    "    if len(Genres) == 0:\n",
    "        return 'Genre not given'\n",
    "    return Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre(Show_URL[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre(Show_URL[76])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARENTAL GUIDLINES..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Parental Guidlines rating shows how suitable a TV series is for viewing by different age groups. Some examples of age restriction tags are TV-MA(mature, adult audiences), TV-14(unsuitable for children under 14 years of age), TV-G(generally suited for all audiences),e.t.c.\n",
    "\n",
    "This information is stored in the span-tag with class name 'certification' in our web page's html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = docu2.find('span', class_ = 'certification').text.strip()\n",
    "age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed that some of the shows don't have this information available, hence i had to modify in the function to deal with such cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewer_suitability(showurl):\n",
    "    # download Show page and create a Beautifulsoup object\n",
    "    doc1 = create_doc(showurl)\n",
    "    \n",
    "    if doc1.find('span', class_ = 'certification') == None:\n",
    "        return \"Not Available\"\n",
    "    ages = doc1.find('span', class_ = 'certification').text.strip()\n",
    "    \n",
    "    return ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_suitability(Show_URL[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_suitability(Show_URL[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOP CASTS ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-2.png](https://i.imgur.com/4unFjl7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The casts tag is in an li-tag of class 'card' which is also in an ol-tag as seen in the image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_tagss = docu2.find_all('li',class_ = 'card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_tagss = docu2.find_all('ol', class_ = 'people scroller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast = []\n",
    "    \n",
    "for ol in ol_tagss:\n",
    "    for li in li_tagss:\n",
    "        # Check if li tags are in ol tags\n",
    "        if li in ol:\n",
    "            # Add all li casts texts to the creator list\n",
    "            cast.append(li.p.text)\n",
    "print(cast)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Series_cast(showurl):\n",
    "   # download Show page and create a Beautifulsoup object\n",
    "    doc1 = create_doc(showurl)\n",
    "   \n",
    "    # Find all ol and li tags\n",
    "    ol_tags = doc1.find_all('ol', class_ = 'people scroller')\n",
    "    li_tags = doc1.find_all('li',class_ = 'card')\n",
    "    \n",
    "    # create a list to add all casts\n",
    "    casts = []\n",
    "    \n",
    "    for ol in ol_tags:\n",
    "        for li in li_tags:\n",
    "            # Check if li tags are in ol tags\n",
    "            if li in ol:\n",
    "                # Add all li cast texts to the casts list\n",
    "                casts.append(li.p.text)\n",
    "                \n",
    "    # If casts names are not given:     \n",
    "    if len(casts) == 0:\n",
    "        return \"Casts name not Given\"\n",
    "    # Return list of casts\n",
    "    return casts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series_cast(Show_URL[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been able to extract details such as the a show's creator(s), an overview of the show, the genre type, age restriction guidlines as well as the top casts. We have also been able to create functions that make it easy to get these infos without writing long lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Show's Information DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a pandas dataframe for the second Series with informations such as:\n",
    "- Series Creator\n",
    "- Genre\n",
    "- Description\n",
    "- Parental Guidlines\n",
    "- Top Casts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_Creators = showmaker(Show_URL[1])\n",
    "Show_Creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overview = Description(Show_URL[1])\n",
    "Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genres = Genre(Show_URL[1]) \n",
    "Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_restriction = viewer_suitability(Show_URL[1])\n",
    "Age_restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Casts = Series_cast(Show_URL[1])\n",
    "print(Casts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use lists in dictionary to create a dataframe for the first show.\n",
    "\n",
    "\n",
    "Firstly, we will create a dictionary that consists of the column names as keys and the informations we just generated as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column ={'Series Creator':Show_Creators, 'Genre':Genres, 'Overview':Overview, 'Age Suitability':Age_restriction, ' Top Casts':Casts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display the full contents of all columns\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "falcon_wintersoldier_df = pd.DataFrame(list(column.items()),columns = ['Item','Details'])\n",
    "falcon_wintersoldier_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that can take any of the Show's URL and return a dataframe containing the above informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shows_df(url):\n",
    "    \n",
    "    # Extract all required info using the created functions\n",
    "    Creator = showmaker(url)\n",
    "    Genres = Genre(url)\n",
    "    Overview = Description(url)\n",
    "    Age_restr = viewer_suitability(url)\n",
    "    Casts = Series_cast(url)\n",
    "    \n",
    "    # To display the full contents of all columns without truncating.\n",
    "    pd.set_option('max_colwidth', None)\n",
    "    \n",
    "    # Create a dataframe\n",
    "    column ={'Series Creator':Creator,\n",
    "             'Genre':Genres, 'Overview':Overview, 'Age Suitability':Age_restr, ' Top Casts':Casts}\n",
    "    return pd.DataFrame(list(column.items()),columns = ['Item','Details'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows_df(Show_URL[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Shows And Create Their CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we will first of all create a function 'create-show-csv' that takes a show's url and title as argument and returns it csv file.\n",
    "\n",
    "At this point, it will be wise to import the os module to help us navigate around files in the system. This module provides a portable way of using operating system dependent functionality. Click the link to learn more.\n",
    "https://docs.python.org/3/library/os.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_show_csv(url,title):\n",
    "    # name of the csv file\n",
    "    filename = title + '.csv'\n",
    "    \n",
    "    # check if file already exists\n",
    "    if os.path.exists(filename):\n",
    "        print('The File {} already exists, skipping...'.format(filename))\n",
    "        return\n",
    "    # create a csv file\n",
    "    dataframe = shows_df(url)\n",
    "    dataframe.to_csv(filename, index = None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a function 'tvshows_csv' that will be able to iterate through all 200 shows and create a csv file for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvshows_csv():\n",
    "    print(\"Scraping top 200 TV shows\")\n",
    "    \n",
    "    df = TV_shows_df\n",
    "    # iterate through our TV_Shows dataframe along rows with column name show link and show title\n",
    "    for index, rows in df.iterrows():\n",
    "        print('Scraping {}...'.format(rows['Show Title']))\n",
    "        create_show_csv(rows['Show Link'], rows['Show Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call our function and see how it goes.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvshows_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see an example of one of the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Am.dad](https://i.imgur.com/zeVc8J0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully scraped all 200 TV Shows, obtained some information about each of them and stored them as a csv file using their names.\n",
    "\n",
    "We can view and even download these files by clicking file-open."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Directory To Store CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a directory/folder where we can store all of these csv files we just created. We will use the os.makedirs() method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder/directory name\n",
    "directory = \"TVShows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent directory path\n",
    "par_dir = \"D:/Web scrapping project\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining both parent and 'child directories'..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(directory, par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(path) \n",
    "print(\"Directory '% s' created\" % directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our folder's been created, we can mark all our csv files and move them into it. Just like in the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![csvs](https://i.imgur.com/ljzcslF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been able to successfully extract some important information on the website https://www.themoviedb.org/tv using web srapping techniques.\n",
    "\n",
    "- We were able to download the web page using requests library and then parse the HTML codes in the downloaded page using the Python BeautifulSoup library.\n",
    "\n",
    "- We used our knowledge of HTML tags to extract some information such as the Show's name, the date it was first released as well as the show's web link.\n",
    "\n",
    "- Because we were interested in getting the top 100 popular shows and realized all 100 were not on our downloaded page, we had to find the link to 4 other pages of the same website (each page contained 20 shows maximum) and download same information as the first page.\n",
    "\n",
    "- We then used the information gotten to create a Pandas dataframe and also saved it as a csv file.\n",
    "\n",
    "- We went further to get informations about all the Shows. The informations include the show's creator, a brief description, the genre, The parental guidlines and top casts. We created a dataframe as well as csv files for these.\n",
    "- Finally, we saved all the generated csv files into a created directory and called it 'TVShows'.\n",
    "\n",
    "Note that in all of this, we were able to write functions that helped us extract these information automatically without having to write long codes for each TV Show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One notable challenge i faced was the duplication of some outputs on the 'Released Date' information. Luckily, we didn't need the released date info to get any other data. Although we had to solve the problem manually, there is need for a programmatic solution in case of larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future work, perhaps we could have a function that will take a show's title as argument and then return all interesting information about that show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- https://stackoverflow.com/questions/44958587/python-beautifulsoup-get-tag-within-a-tag\n",
    "- https://www.geeksforgeeks.org/create-a-pandas-dataframe-from-lists/\n",
    "- https://towardsdatascience.com/how-to-show-all-columns-rows-of-a-pandas-dataframe-c49d4507fcf\n",
    "- https://jovian.ai/learn/zero-to-data-analyst-bootcamp/assignment/project-1-web-scraping-with-python\n",
    "- https://www.geeksforgeeks.org/python-itertools-chain/#:~:text=chain()%20function,thus%20explicitly%20converted%20into%20iterables.\n",
    "- https://stackoverflow.com/questions/716477/join-list-of-lists-in-python\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-using-tag-names\n",
    "- https://www.geeksforgeeks.org/create-a-directory-in-python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
